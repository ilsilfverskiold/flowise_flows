{
  "nodes": [
    {
      "id": "supervisor_0",
      "position": {
        "x": -1850.5716048691042,
        "y": -385.34651753742787
      },
      "type": "customNode",
      "data": {
        "id": "supervisor_0",
        "label": "Supervisor",
        "version": 3,
        "name": "supervisor",
        "type": "Supervisor",
        "baseClasses": [
          "Supervisor"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Supervisor Name",
            "name": "supervisorName",
            "type": "string",
            "placeholder": "Supervisor",
            "default": "Supervisor",
            "id": "supervisor_0-input-supervisorName-string"
          },
          {
            "label": "Supervisor Prompt",
            "name": "supervisorPrompt",
            "type": "string",
            "description": "Prompt must contains {team_members}",
            "rows": 4,
            "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
            "additionalParams": true,
            "id": "supervisor_0-input-supervisorPrompt-string"
          },
          {
            "label": "Summarization",
            "name": "summarization",
            "type": "boolean",
            "description": "Return final output as a summarization of the conversation",
            "optional": true,
            "additionalParams": true,
            "id": "supervisor_0-input-summarization-boolean"
          },
          {
            "label": "Recursion Limit",
            "name": "recursionLimit",
            "type": "number",
            "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
            "default": 100,
            "additionalParams": true,
            "id": "supervisor_0-input-recursionLimit-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
            "id": "supervisor_0-input-model-BaseChatModel"
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "supervisor_0-input-agentMemory-BaseCheckpointSaver"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "supervisor_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "supervisorName": "Supervisor",
          "supervisorPrompt": "You are a tech research supervisor responsible for directing a team of analysts, a researcher and a summerizer. You have access to a few endpoints based on what the question is via different analysts. \n\nThe first thing you always want to do is ask the tech_researcher what the steps that should be based on a question that is coming from the user and based on the previous conversation, summarize and then give the researcher the question on what should be done from here. \n\nFrom then you can delegate what can be done to 4 different analysts that have access to different data. You need to make sure you send the correct information, such as the specific keywords and/or time period the researcher gave. If you do not do this then it will not be able to make the correct analysis.\n\nLastly when you have gathered all the information you will use the summarizing analyst to send it to, so it can create a story of it for the user. Make sure you send all statics and sources (texts and links) to this agent so they can do their job correctly. \n\nIn total you have access to the following workers: {team_members}. \n\nGiven the following user request, respond with the worker to act next.\n\nEach worker will perform a task and respond with their results and status. You should always go to the tech researcher to get an idea what the next step should be and to understand better which worker that should act next.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.\nEnd your tasks by responding with \"FINISH\".\n\n\n\n\n\n\n\n",
          "model": "{{chatOpenAI_0.data.instance}}",
          "agentMemory": "{{agentMemory_0.data.instance}}",
          "summarization": true,
          "recursionLimit": "100",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "supervisor_0-output-supervisor-Supervisor",
            "name": "supervisor",
            "label": "Supervisor",
            "description": "",
            "type": "Supervisor"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 483,
      "selected": false,
      "positionAbsolute": {
        "x": -1850.5716048691042,
        "y": -385.34651753742787
      },
      "dragging": false
    },
    {
      "id": "worker_0",
      "position": {
        "x": -438.0165558619117,
        "y": 166.05214648270265
      },
      "type": "customNode",
      "data": {
        "id": "worker_0",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_0-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_0-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_0-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_0-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_0-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Trending Keywords Analyst",
          "workerPrompt": "You are an assistant tasked with fetching trending and top keywords in tech for specified periods ('daily', 'weekly', 'monthly', or 'quarterly') using the \"safron_keywords\" tool. You do not fabricate information but simply gather data from the tool. You never add on information that has not been provided. Execute your tasks as follows:\n\nCategory Requests: When you receive a request specifying a category (like \"tools\" or \"platforms\"), make a single API call for that category to retrieve all relevant keywords. This call will provide a comprehensive list of keywords for the category, eliminating the need for subsequent keyword-specific calls.\n\nSpecific Keyword Requests: If the request specifically mentions a keyword, use that keyword to make a direct call to fetch its data. This ensures that you are only gathering information specific to that keyword without fetching broad category data first.\n\nCategories include:\n\n\"companies\": Companies & Organizations, e.g., Tesla, OpenAI.\n\"tools\": Tools & Services, e.g., ECS, GitHub Copilot.\n\"platforms\": Platforms & Search Engines, e.g., AWS, DigitalOcean.\n\"hardware\": Hardware & Systems, e.g., MacBook, Ubuntu.\n\"frameworks\": Software frameworks & libraries, e.g., Pytorch, Bootstrap.\n\"languages\": Software Languages & Syntax, e.g., JavaScript, C#.\n\"ai\": AI Models & Assistants, e.g., ChatGPT, Google Gemini.\n\"websites\": Websites & Applications, e.g., Reddit, YouTube.\n\"people\": Prominent figures, e.g., Elon Musk, Sam Altman.\n\"subjects\": Topics of discussion, e.g., AI, Privacy.\n\"concepts\": Concepts & Methods, e.g., API, NLP.\nClarify your actions based on the type of request:\n\nBroad Categories: If the request is for \"Trending tools\" or similar broad categories, use the category to fetch all associated keywords in one call.\nSpecific Keywords: If the request is for a specific keyword, directly search using that keyword.\nAlways base your responses on actual data from the \"safron_keywords\" tool. Clearly state if no data is available. Provide complete data with metrics such as count, engagement, and sentiment for analysis. Avoid redundant calls by not querying the tool for keywords after retrieving them in a category search.\n",
          "tools": [
            "{{customTool_0.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "{{chatOpenAI_1.data.instance}}",
          "promptValues": "",
          "maxIterations": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -438.0165558619117,
        "y": 166.05214648270265
      },
      "dragging": false
    },
    {
      "id": "customTool_0",
      "position": {
        "x": -549.2628959553347,
        "y": -706.313188809688
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_0-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_0-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "ef481de5-b4fc-4f20-9a4e-a1e644bc7044",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 372,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -549.2628959553347,
        "y": -706.313188809688
      }
    },
    {
      "id": "agentMemory_0",
      "position": {
        "x": -907.5867721225641,
        "y": -670.0438162450529
      },
      "type": "customNode",
      "data": {
        "id": "agentMemory_0",
        "label": "Agent Memory",
        "version": 1,
        "name": "agentMemory",
        "type": "AgentMemory",
        "baseClasses": [
          "AgentMemory",
          "BaseCheckpointSaver"
        ],
        "category": "Memory",
        "description": "Memory for agentflow to remember the state of the conversation",
        "inputParams": [
          {
            "label": "Database",
            "name": "databaseType",
            "type": "options",
            "options": [
              {
                "label": "SQLite",
                "name": "sqlite"
              }
            ],
            "default": "sqlite",
            "id": "agentMemory_0-input-databaseType-options"
          },
          {
            "label": "Database File Path",
            "name": "databaseFilePath",
            "type": "string",
            "placeholder": "C:\\Users\\User\\.flowise\\database.sqlite",
            "description": "If SQLite is selected, provide the path to the SQLite database file. Leave empty to use default application database",
            "additionalParams": true,
            "optional": true,
            "id": "agentMemory_0-input-databaseFilePath-string"
          },
          {
            "label": "Additional Connection Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "agentMemory_0-input-additionalConfig-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "databaseType": "sqlite",
          "databaseFilePath": "",
          "additionalConfig": ""
        },
        "outputAnchors": [
          {
            "id": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
            "name": "agentMemory",
            "label": "AgentMemory",
            "description": "Memory for agentflow to remember the state of the conversation",
            "type": "AgentMemory | BaseCheckpointSaver"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 328,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -907.5867721225641,
        "y": -670.0438162450529
      }
    },
    {
      "id": "worker_2",
      "position": {
        "x": -62.13871633835012,
        "y": 164.4777037360662
      },
      "type": "customNode",
      "data": {
        "id": "worker_2",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_2-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_2-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_2-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_2-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_2-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_2-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_2-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Analyze Texts Analyst",
          "workerPrompt": "You are an assistant that will use the tool \"safron_sources\" to get back exact sources (texts and links) for each keyword. Remember to use the exact keyword given and no other versions of it, as that will give you limited results. If you do not get back any results make sure you've used the correct time period and then try again. You may not under any circumstances fabricate sources. If you are getting back an error or no resuls then you will simply say that you could not fetch the sources for the keyword(s).\n\nYou may use the \"safron_sources\" tool as many times as needed, for as many keywords that have been provided. If you do not get back any results make sure you've used the correct time period and then try again. Try until you have gotten the sources from the \"safron_sources\" tool. Do not fabricate sources that does not exist.",
          "tools": [
            "{{customTool_5.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "{{chatOpenAI_1.data.instance}}",
          "promptValues": "",
          "maxIterations": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -62.13871633835012,
        "y": 164.4777037360662
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -1990.5244119419585,
        "y": -1131.5546059323112
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 6,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, Conversational Agent, Tool Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o",
          "temperature": "0.2",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": -1990.5244119419585,
        "y": -1131.5546059323112
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_1",
      "position": {
        "x": -1653.8191461828528,
        "y": -1135.5056083122536
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_1",
        "label": "ChatOpenAI",
        "version": 6,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_1-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_1-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_1-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, Conversational Agent, Tool Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_1-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_1-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_1-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.2",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 670,
      "selected": false,
      "positionAbsolute": {
        "x": -1653.8191461828528,
        "y": -1135.5056083122536
      },
      "dragging": false
    },
    {
      "id": "worker_3",
      "position": {
        "x": -1200.4201826782705,
        "y": 160.47994138443113
      },
      "type": "customNode",
      "data": {
        "id": "worker_3",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_3-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_3-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_3-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_3-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_3-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_3-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_3-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Connected Keywords Analyst",
          "workerPrompt": "You will be given one or several keywords, your task is to use the \"fetch_connected_keywords\" tool for each keyword  to get back statistics around trending and top keywords for a time period. It is important that you use the specific keywords when using the \"fetch_connected_keywords\" tool, so if the supervisor is giving you the keyword \"ChatGPT\" and \"Claude\" you use those keywords and not just \"AI\" as that will not get you back results for \"ChatGPT\" and \"Claude\" specifically.\n\nYou can query this tool as much as you need to, to get an understanding of the top and trending keywords connected to the keyword. But don't over use it, if you get two keywords use it two times. Always use the tool for each keyword and not together. I.e. if you get the keywords \"AWS, Elon Musk\" you will use the tool seperately on \"AWS\" and then again on \"Elon Musk\" and then send back data. \n\nNever fabricate information, statistics or keywords but always use the \"fetch_connected_keywords\" tool to get correct data for the specific keywords you are handed.",
          "tools": [
            "{{customTool_3.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "{{chatOpenAI_1.data.instance}}",
          "promptValues": "",
          "maxIterations": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -1200.4201826782705,
        "y": 160.47994138443113
      },
      "dragging": false
    },
    {
      "id": "customTool_3",
      "position": {
        "x": -549.5568425144868,
        "y": -286.2495176759264
      },
      "type": "customNode",
      "data": {
        "id": "customTool_3",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_3-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_3-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "7aa4bddc-f654-486f-ab68-213ec5da9408",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_3-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 372,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -549.5568425144868,
        "y": -286.2495176759264
      }
    },
    {
      "id": "worker_4",
      "position": {
        "x": -830.8129500005897,
        "y": 160.96578868887457
      },
      "type": "customNode",
      "data": {
        "id": "worker_4",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_4-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_4-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_4-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_4-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_4-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_4-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_4-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Graphing Keywords Analyst",
          "workerPrompt": "You are an assistant that is tasked with getting back keyword statistics via the \"graphing_keywords\" tool. This tool can be used to get back statistics for a keyword over time. You will be given keyword(s) and a time period and you are thus tasked with using the \"graphing_keywords\" tool for each keyword once each and then handing back the data that has been given. \n\nYou may use the \"graphing_keywords\" tool as much as you need to, but do not iterate for the same keyword over and over once you have the data you need. If you only have one keyword, then you only need to call  \"graphing_keywords\" tool once successfully.\n\nThe time periods will aggregate data differently, the daily will get you back data by day, the weekly will get you data back per 3 days, the monthly will get you back data by week and quarterly will get you data back by every two weeks. Make sure you communicate this clearly with the supervisor.\n\n",
          "tools": [
            "{{customTool_4.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "{{chatOpenAI_1.data.instance}}",
          "promptValues": "",
          "maxIterations": "20"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -830.8129500005897,
        "y": 160.96578868887457
      },
      "dragging": false
    },
    {
      "id": "customTool_4",
      "position": {
        "x": -199.7248023308544,
        "y": -698.9378211357523
      },
      "type": "customNode",
      "data": {
        "id": "customTool_4",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_4-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_4-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "6d1ae262-e9f7-42e9-944a-30e850fb7d43",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_4-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 372,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -199.7248023308544,
        "y": -698.9378211357523
      }
    },
    {
      "id": "worker_5",
      "position": {
        "x": -1945.3566738977713,
        "y": 158.70591385746735
      },
      "type": "customNode",
      "data": {
        "id": "worker_5",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_5-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_5-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_5-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_5-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_5-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_5-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_5-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Tech Researcher",
          "workerPrompt": "You are a tech researcher, you are tasked with telling the supervisor what it should do with a question that is coming in from a user. A user can ask for things such as \"what is trending yesterday or this month\" or \"I want to explore RAG and what's new there\" or \"I'm in product management in tech I need an update.\" You are tasked with figuring out what steps the supervisor should take to achieve the correct goal. \n\nYou have 4 choices to work with. \n\n1. You can use the \"keyword_trends_analyst\", to get back statistics for a period (daily, weekly, monthly or quarterly) based on either a category (Companies & Organizations, Tools & Services, Platforms & Search Engines, Hardware & Systems, Frameworks & Libraries, Languages & Syntax, AI Models & Assistants, Websites & Applications, People, Subjects, Concepts & Methods, and Bucket (other)), search with a keyword (such as OpenAI or Open Source) or sentiment (negative, positive or neutral).\n\n2. You can use the \"analyze_texts_analyst\", to get back the exact sources (texts and links) for each keyword based on a period or if you just want to do broad search you can skip the period and say 'no period'. This step is very important if the user is asking what they are saying for a keyword. I.e. if Starlink is trending, then the user wants to understand why it is so and to understand what has been said as well as to get links back. This is how we provide relevant data to the user.\n\n3. You can use the \"connected_keyword_analyst\" to see how a keyword connects to other keywords. This step can be great when a user is asking for a specific keyword and we need to understand what they mean by it. If a user asks what is happing around \"RAG\" then you can also check similar keyword statistics around this word. You can then use the \"analyze_texts_analyst\" to get back sources for each keyword to summarize what has been said for the connecting keywords as well. As an example, for the keyword \"RAG\" you might get back \"AI\", \"Generative AI\", \"GraphRAG\" and \"Chunkit\" from the \"connected_keyword_analyst\" as trending and these keywords you may want to query to get back the exact texts as well so the user can understand how it is connected.\n\n4. You can use the \"graphing_keyword_analyst\" to get back more data for specific keywords. This enables you to build tables with the data so the user can understand how mentions has progressed day by day. An example would be to query \"OpenAI\" for the period \"quarterly\" and then see its exact mentions seperated by week for the last 6 months. \n\n5. You can use the \"summarizing_analyst\" at the end, after all analysts have sent back the correct information, to neatly summarize the data that has been picked up by the other agents setting up tables, summarizing what has been said, and setting up graphs. Please make sure to tell the supervisor that it needs to send all data that has been picked up to this summarizer so it can do its job properly.\n\nRemember that if the user is asking for statistics around a specific keyword rather than trends or top keywords as a whole it may be better to get statistics from \"graphing_keyword_analyst\" for the keyword specifically rather than the \"keyword_trends_analyst\". Also remember if the user is asking for what is trending for the week or daily you also want to make sure to tell the supervisor to use both \"keyword_trends_analyst\" and the \"analyze_texts_analyst\" to understand what has been said.\n\nYour task is to tell the supervisor all the steps it should take now with the user question.",
          "tools": [],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": "3"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -1945.3566738977713,
        "y": 158.70591385746735
      },
      "dragging": false
    },
    {
      "id": "customTool_5",
      "position": {
        "x": -196.35838983492465,
        "y": -287.2561310499907
      },
      "type": "customNode",
      "data": {
        "id": "customTool_5",
        "label": "Custom Tool",
        "version": 2,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_5-input-selectedTool-asyncOptions"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "description": "Return the output of the tool directly to the user",
            "type": "boolean",
            "optional": true,
            "id": "customTool_5-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "4a09c655-2855-4421-8524-a83646ed3b3f",
          "returnDirect": ""
        },
        "outputAnchors": [
          {
            "id": "customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 372,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -196.35838983492465,
        "y": -287.2561310499907
      }
    },
    {
      "id": "worker_6",
      "position": {
        "x": -1590.462104719452,
        "y": 158.04098331521345
      },
      "type": "customNode",
      "data": {
        "id": "worker_6",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_6-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_6-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_6-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_6-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_6-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_6-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_6-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Summarizing Analyst",
          "workerPrompt": "You are a summarizing analyst, that will be the assistant who will summarize all the data that has been gathered so far for a user question. You do not simply output a bunch of data but you clearly summarize what the data says to tell a story for each keyword and as a whole. You will get back statistics and sources (texts and links) to be able to accurately summarize and present this information so it can be digested based on a user question. Remember to look at the sources and summarize for the user so they do not have to read each and every source on their own. You will never fabricate or make up statistics, sources and keywords but simply summarize the data you are provided with.",
          "tools": [],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": "3"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 722,
      "selected": false,
      "positionAbsolute": {
        "x": -1590.462104719452,
        "y": 158.04098331521345
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_0",
      "targetHandle": "worker_0-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "worker_0",
      "targetHandle": "worker_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-worker_0-worker_0-input-tools-Tool"
    },
    {
      "source": "agentMemory_0",
      "sourceHandle": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-agentMemory-BaseCheckpointSaver",
      "type": "buttonedge",
      "id": "agentMemory_0-agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver-supervisor_0-supervisor_0-input-agentMemory-BaseCheckpointSaver"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_2",
      "targetHandle": "worker_2-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_2-worker_2-input-supervisor-Supervisor"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_3",
      "targetHandle": "worker_3-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_3-worker_3-input-supervisor-Supervisor"
    },
    {
      "source": "chatOpenAI_1",
      "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "worker_3",
      "targetHandle": "worker_3-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-worker_3-worker_3-input-model-BaseChatModel"
    },
    {
      "source": "customTool_3",
      "sourceHandle": "customTool_3-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "worker_3",
      "targetHandle": "worker_3-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_3-customTool_3-output-customTool-CustomTool|Tool|StructuredTool|Runnable-worker_3-worker_3-input-tools-Tool"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_4",
      "targetHandle": "worker_4-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_4-worker_4-input-supervisor-Supervisor"
    },
    {
      "source": "customTool_4",
      "sourceHandle": "customTool_4-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "worker_4",
      "targetHandle": "worker_4-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_4-customTool_4-output-customTool-CustomTool|Tool|StructuredTool|Runnable-worker_4-worker_4-input-tools-Tool"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_5",
      "targetHandle": "worker_5-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_5-worker_5-input-supervisor-Supervisor"
    },
    {
      "source": "customTool_5",
      "sourceHandle": "customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "worker_2",
      "targetHandle": "worker_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_5-customTool_5-output-customTool-CustomTool|Tool|StructuredTool|Runnable-worker_2-worker_2-input-tools-Tool"
    },
    {
      "source": "chatOpenAI_1",
      "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "worker_2",
      "targetHandle": "worker_2-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-worker_2-worker_2-input-model-BaseChatModel"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_6",
      "targetHandle": "worker_6-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_6-worker_6-input-supervisor-Supervisor"
    },
    {
      "source": "chatOpenAI_1",
      "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "worker_4",
      "targetHandle": "worker_4-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-worker_4-worker_4-input-model-BaseChatModel"
    },
    {
      "source": "chatOpenAI_1",
      "sourceHandle": "chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "worker_0",
      "targetHandle": "worker_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_1-chatOpenAI_1-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-worker_0-worker_0-input-model-BaseChatModel"
    }
  ]
}